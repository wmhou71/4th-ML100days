{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業重點]\n",
    "了解線性回歸的模型發展歷程，並了解優勢與劣勢，以及其使用情境  \n",
    "\n",
    "## 作業  \n",
    "請閱讀以下相關文獻，並回答以下問題   \n",
    "\n",
    "Linear Regression 詳細介紹  \n",
    "https://brohrer.mcknote.com/zh-Hant/how_machine_learning_works/how_linear_regression_works.html  \n",
    "\n",
    "Logistics Regression 詳細介紹  \n",
    "https://medium.com/@yehjames/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-3%E8%AC%9B-%E7%B7%9A%E6%80%A7%E5%88%86%E9%A1%9E-%E9%82%8F%E8%BC%AF%E6%96%AF%E5%9B%9E%E6%AD%B8-logistic-regression-%E4%BB%8B%E7%B4%B9-a1a5f47017e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.線性回歸模型能夠準確預測非線性關係的資料集嗎?  \n",
    "Linear regression是使用線性的方式來擬和資料，即使有很多參數，預測表現仍有限。  \n",
    "Logistic Regression 雖然是廣義的線性模型，但經過 Sigmoid 函數以及 kernel trick，是可以解決非線性問題的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.回歸模型是否對資料分布有基本假設? \n",
    "針對資料有如下五個基本假設，即使資料不符合基本假設一樣能夠訓練。\n",
    "i.線性性 & 可加性\n",
    "ii.誤差項（ε）間相互獨立\n",
    "iii.自變量(X1,X2)間相互獨立\n",
    "iv.誤差項（ε）的方差為常數。\n",
    "v.誤差項（ε）應成常態分佈\n",
    "https://blog.csdn.net/Noob_daniel/article/details/76087829"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

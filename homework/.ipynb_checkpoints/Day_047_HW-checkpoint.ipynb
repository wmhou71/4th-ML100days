{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        48\n",
      "          1       0.97      0.95      0.96        39\n",
      "          2       1.00      0.98      0.99        48\n",
      "          3       0.98      0.93      0.95        43\n",
      "          4       1.00      0.95      0.98        42\n",
      "          5       0.96      0.96      0.96        49\n",
      "          6       0.97      0.95      0.96        39\n",
      "          7       0.98      1.00      0.99        49\n",
      "          8       0.88      0.98      0.92        43\n",
      "          9       0.96      0.96      0.96        50\n",
      "\n",
      "avg / total       0.97      0.96      0.96       450\n",
      "\n",
      "Acuuracy:  0.9644444444444444\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset DIGITS, and bulid an estimating model\n",
    "digits = datasets.load_digits()\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=4)\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print (metrics.classification_report(y_test, y_pred))\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "#Get GradientBoostingClassifier's parameters\n",
    "print(clf.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Specify values to grid search over\n",
    "n_estimators = [100, 200, 300]\n",
    "max_depth = [1, 3, 5]\n",
    "max_features = [None, 'sqrt', 'log2']\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_depth' : max_depth,\n",
    "    'max_features': max_features    \n",
    "}\n",
    " \n",
    "# Grid search using cross-validation\n",
    "gridCV = GridSearchCV(GradientBoostingClassifier(), param_grid=hyperparameters, cv=10, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing n_estimators value is: 300\n",
      "The best performing max_depth value is: 3\n",
      "The best performing max_features value is: log2\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search with 10-fold CV\n",
    "gridCV.fit(x_train, y_train)\n",
    " \n",
    "# Identify optimal hyperparameter values\n",
    "best_n_estim      = gridCV.best_params_['n_estimators']\n",
    "best_max_depth    = gridCV.best_params_['max_depth']\n",
    "best_max_features = gridCV.best_params_['max_features']  \n",
    " \n",
    "print(\"The best performing n_estimators value is: {}\".format(best_n_estim))\n",
    "print(\"The best performing max_depth value is: {}\".format(best_max_depth))\n",
    "print(\"The best performing max_features value is: {}\".format(best_max_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        48\n",
      "          1       0.97      0.97      0.97        39\n",
      "          2       1.00      1.00      1.00        48\n",
      "          3       0.95      0.98      0.97        43\n",
      "          4       1.00      1.00      1.00        42\n",
      "          5       0.98      0.98      0.98        49\n",
      "          6       1.00      0.97      0.99        39\n",
      "          7       1.00      1.00      1.00        49\n",
      "          8       0.98      0.98      0.98        43\n",
      "          9       0.98      0.98      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       450\n",
      "\n",
      "Acuuracy:  0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "# Train classifier by optimal hyperparameter values\n",
    "clf = GradientBoostingClassifier(n_estimators=best_n_estim, max_depth=best_max_depth, max_features=best_max_features)\n",
    " \n",
    "clf.fit(x_train, y_train)\n",
    "y_pred  = clf.predict(x_test)\n",
    " \n",
    "print (metrics.classification_report(y_test, y_pred))\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. https://cambridgecoding.wordpress.com/2016/04/03/scanning-hyperspace-how-to-tune-machine-learning-models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
